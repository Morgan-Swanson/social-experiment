name: Deploy to Production

on:
  push:
    branches:
      - main
  workflow_dispatch:  # Allow manual trigger

env:
  AWS_REGION: us-east-1
  TF_STATE_BUCKET: social-experiment-terraform-state
  TF_LOCK_TABLE: social-experiment-terraform-locks

jobs:
  deploy:
    name: Deploy to AWS Production
    runs-on: ubuntu-latest
    
    env:
      TF_VAR_environment: cloud
      TF_VAR_project_name: social-experiment
      TF_VAR_aws_region: us-east-1
      TF_VAR_github_repo: Morgan-Swanson/social-experiment
      TF_VAR_github_branch: main
      TF_VAR_nextauth_secret: ${{ secrets.TF_VAR_nextauth_secret }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1
      
      - name: Create Terraform State Infrastructure
        run: |
          # Create S3 bucket for state if it doesn't exist
          if ! aws s3api head-bucket --bucket $TF_STATE_BUCKET 2>/dev/null; then
            echo "Creating S3 bucket for Terraform state..."
            aws s3api create-bucket --bucket $TF_STATE_BUCKET --region $AWS_REGION
            aws s3api put-bucket-versioning --bucket $TF_STATE_BUCKET --versioning-configuration Status=Enabled
            aws s3api put-bucket-encryption --bucket $TF_STATE_BUCKET --server-side-encryption-configuration '{"Rules":[{"ApplyServerSideEncryptionByDefault":{"SSEAlgorithm":"AES256"}}]}'
            aws s3api put-public-access-block --bucket $TF_STATE_BUCKET --public-access-block-configuration "BlockPublicAcls=true,IgnorePublicAcls=true,BlockPublicPolicy=true,RestrictPublicBuckets=true"
            echo "S3 bucket created successfully"
          else
            echo "S3 bucket already exists"
          fi
          
          # Create DynamoDB table for state locking if it doesn't exist
          if ! aws dynamodb describe-table --table-name $TF_LOCK_TABLE 2>/dev/null; then
            echo "Creating DynamoDB table for state locking..."
            aws dynamodb create-table \
              --table-name $TF_LOCK_TABLE \
              --attribute-definitions AttributeName=LockID,AttributeType=S \
              --key-schema AttributeName=LockID,KeyType=HASH \
              --billing-mode PAY_PER_REQUEST \
              --region $AWS_REGION
            echo "Waiting for DynamoDB table to be active..."
            aws dynamodb wait table-exists --table-name $TF_LOCK_TABLE
            echo "DynamoDB table created successfully"
          else
            echo "DynamoDB table already exists"
          fi
      
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.6.0
      
      - name: Terraform Init
        working-directory: ./terraform
        run: |
          terraform init \
            -backend-config="bucket=$TF_STATE_BUCKET" \
            -backend-config="key=terraform.tfstate" \
            -backend-config="region=$AWS_REGION" \
            -backend-config="dynamodb_table=$TF_LOCK_TABLE" \
            -backend-config="encrypt=true"
      
      - name: Import Existing Resources
        working-directory: ./terraform
        continue-on-error: true
        run: |
          # Import existing resources if they exist but aren't in state
          # These commands will fail gracefully if resources don't exist or are already imported
          
          echo "Checking for existing resources to import..."
          
          # Import VPC if exists
          VPC_ID=$(aws ec2 describe-vpcs --filters "Name=tag:Name,Values=social-experiment-vpc" --query 'Vpcs[0].VpcId' --output text 2>/dev/null || echo "None")
          if [ "$VPC_ID" != "None" ] && [ "$VPC_ID" != "" ]; then
            terraform import 'module.cloud[0].aws_vpc.main' "$VPC_ID" 2>/dev/null || echo "VPC already in state or import failed"
          fi
          
          # Import S3 bucket if exists
          if aws s3api head-bucket --bucket social-experiment-storage-423231905077 2>/dev/null; then
            terraform import 'module.cloud[0].aws_s3_bucket.storage' "social-experiment-storage-423231905077" 2>/dev/null || echo "S3 bucket already in state or import failed"
          fi
          
          # Import IAM roles if exist
          if aws iam get-role --role-name social-experiment-app-role 2>/dev/null; then
            terraform import 'module.cloud[0].aws_iam_role.app' "social-experiment-app-role" 2>/dev/null || echo "App role already in state or import failed"
          fi
          
          if aws iam get-role --role-name social-experiment-amplify-role 2>/dev/null; then
            terraform import 'module.cloud[0].aws_iam_role.amplify' "social-experiment-amplify-role" 2>/dev/null || echo "Amplify role already in state or import failed"
          fi
          
          # Import Secrets Manager secrets if exist
          if aws secretsmanager describe-secret --secret-id "social-experiment/database-url" 2>/dev/null; then
            terraform import 'module.cloud[0].aws_secretsmanager_secret.database_url' "social-experiment/database-url" 2>/dev/null || echo "Database secret already in state or import failed"
          fi
          
          if aws secretsmanager describe-secret --secret-id "social-experiment/nextauth-secret" 2>/dev/null; then
            terraform import 'module.cloud[0].aws_secretsmanager_secret.nextauth_secret' "social-experiment/nextauth-secret" 2>/dev/null || echo "NextAuth secret already in state or import failed"
          fi
          
          # Import CloudWatch log group if exists
          if aws logs describe-log-groups --log-group-name-prefix "/aws/amplify/social-experiment" --query 'logGroups[0].logGroupName' --output text 2>/dev/null | grep -q "social-experiment"; then
            terraform import 'module.cloud[0].aws_cloudwatch_log_group.app' "/aws/amplify/social-experiment" 2>/dev/null || echo "Log group already in state or import failed"
          fi
          
          # Import DB subnet group if exists
          if aws rds describe-db-subnet-groups --db-subnet-group-name social-experiment-db-subnet 2>/dev/null; then
            terraform import 'module.cloud[0].aws_db_subnet_group.main' "social-experiment-db-subnet" 2>/dev/null || echo "DB subnet group already in state or import failed"
          fi
          
          echo "Import check complete"
      
      - name: Terraform Plan
        working-directory: ./terraform
        run: terraform plan -out=tfplan
      
      - name: Terraform Apply
        working-directory: ./terraform
        run: terraform apply -auto-approve tfplan
      
      - name: Output Deployment Info
        working-directory: ./terraform
        run: |
          echo "## Deployment Complete!" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Infrastructure Outputs:" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Amplify URL:** \`$(terraform output -raw amplify_default_domain 2>/dev/null || echo 'pending')\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**S3 Bucket:** \`$(terraform output -raw storage_bucket 2>/dev/null || echo 'pending')\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Database Endpoint:** \`$(terraform output -raw db_instance_endpoint 2>/dev/null || echo 'pending')\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Next Steps:" >> $GITHUB_STEP_SUMMARY
          echo "1. Connect GitHub to Amplify in AWS Console (first deployment only)" >> $GITHUB_STEP_SUMMARY
          echo "2. Add environment variables to Amplify (check Secrets Manager)" >> $GITHUB_STEP_SUMMARY
          echo "3. Trigger first Amplify deployment" >> $GITHUB_STEP_SUMMARY